# MasterArbeit
Master Thesis: Corporate Bond Returns Prediction
# Step by Step Recreation
**Step1**: Download the data from WRDS for Bond Trades (Trace Enhanced), Mergent FISD (Bond Features, in our case provided by Prof.) Equity data and ratings (Capital IQ), and lastly from FRED for Macro Economic data. All the links to download the exact data are provided in the cleaning_and_creating_final_dataset.py file. Therefore When you download the data and put it in top directory and run the cleaning_and_creating_final_dataset.py. It will clean all the data and create the final Daatset in the data folder. The data folder is only for final data. All the other saving of data like for plots or feature importance or different train and test set will be saved in top directory. Moreover, to run the script in memory specially for Bond trades please check in cleaning_and_creating_final_dataset.py which fileds you should download. We have written it in detail in the comments.

**Step2:**: Once the Data is Downloaded you can do the EDA analysis in the EDA notebook to get the intial feeling of variables in terms of correlations, variables distribution, return distribution, summary statistics,  missing value anaylsis and last but not least a intial fit or so called naive fit to see how the modeeling can be started

**Step3**: After the first two steps, Actual modelling can be done with tb_models.py and ts_models.py. These scripts will take the final_dataset from data folder and run three use cases for 1) Bond and Macro features, 2) Equity Features 3) Bond, Macro and Equity features.  They will output predictions and feature importance and details about the models. and after the run they both will create a directory called AutogluonModels where all the models will be saved and can be loaded individually or only best model to do predictions on out of sample data, generate leaderboards and feature_importance. There are two scripts because one (ts_models.py) is doing strick time series modelling for all the linear and tree based models (Random Forest, XGboost, LightGBM, Weighted Enssembling, etc..) and lastly the neural network TFT. However, the other script tb_models.py run only the linear and tree based models as autogluon provides the Tabular  Predictor(https://auto.gluon.ai/stable/tutorials/tabular/index.html) and Time Series Predictor (https://auto.gluon.ai/stable/tutorials/timeseries/index.html) whereas for tree based and linear models for time series under the hood is tabular predictor therefore to compare performance both are done individually. The rest of the requirements are detailed in comments in the scripts.

# Dependencies
Anaconda Distribution with Python 3.9 or higher 

AutoGluon: It is very important because all the EDA and Modeleing is based on this library and can be installed from https://auto.gluon.ai/stable/install.html
